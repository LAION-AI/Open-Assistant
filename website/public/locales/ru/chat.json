{
  "add_plugin": "Добавить Плагин",
  "back_to_chat_list": "Вернуться к диалогам",
  "chat_date": "{{val, datetime}}",
  "config_title": "Настройки диалога",
  "delete_chat": "Удалить диалог",
  "delete_confirmation": "Вы уверены, что хотите удалить этот диалог?",
  "delete_confirmation_detail": "После того, как вы удалите этот чат, его содержание также будет удалено с серверов, и мы не сможем использовать эти данные, чтобы улучшить наши модели. Пожалуйста, уделяйте время тому, чтобы оценивать ответы в других чатах, это поможет нам сделать Open Assistant лучше!",
  "draft": "Черновик",
  "drafts_generating_notify": "Черновики сообщений все еще генерируются. Пожалуйста, подождите.",
  "edit_plugin": "Редактировать Плагин",
  "empty": "(без названия)",
  "input_placeholder": "Напишите Ассистенту...",
  "login_message": "Чтобы воспользоваться диалогами, вам нужно повторно войти. Используйте один из способов ниже:",
  "max_new_tokens": "Максимальное кол-во новых токенов",
  "model": "Модель",
  "more_actions": "Дополнительные параметры...",
  "only_visible": "Только Видимые",
  "opt_out": {
    "button": "Отказ от предоставления данных для обучения",
    "success_message": "Вы отказались от предоставления данных для обучения.",
    "dialog": {
      "title": "Подтверждение отказа от предоставления данных для обучения",
      "description": "Если вы подтвердите, то этот чат не будет использован для улучшения нашей модели. Пожалуйста, уделяйте время тому, чтобы оценивать ответы в других чатах, чтобы помочь нам сделать Open Assistant лучше!"
    }
  },
  "parameter_description": {
    "max_new_tokens": "Максимальное количество новых токенов: Этот параметр указывает модели, сколько максимум новых токенов она должна сгенерировать для ответа.",
    "repetition_penalty": "Штраф за повторение: Этот параметр уменьшает вероятность повторения одних и тех же токенов снова и снова, делая повторение токенов менее вероятным, чем обычно.",
    "temperature": "Температура: Каждый генерируемый вами токен выбирается из распределения p(next_token|previous_tokens). Параметр температуры может \"обострить\" или ослабить это распределение. Установка значения 1 означает, что модель генерирует токены на основе их предсказанной вероятности (т.е. если модель предсказывает, что \"XYZ\" имеет вероятность 12.3%, она будет генерировать его с вероятностью 12.3%). Понижение температуры до нуля делает модель более жадной, заставляя высокие вероятности становиться еще выше, а низкие — еще ниже (обратите внимание, что это не линейная зависимость!). Повышение температуры делает все вероятности более схожими. Интуитивно понятно, что низкая температура означает, что модель генерирует ответы, соответствующие ее убеждениям, в то время как высокая температура позволяет получить более творческие и разнообразные ответы.",
    "top_k": "Top-k: Это похоже на выборку top-p, но вместо того, чтобы брать верхние токены, пока их суммарная вероятность не превысит 'p', берется только K наиболее вероятных токенов. Top-p обычно предпочтительнее, поскольку позволяет модели \"настраивать\" радиус поиска, но top-k может быть полезен в качестве аварийной ситуации, когда модель не знает, что генерировать дальше, и присваивает многим лексемам очень равномерное распределение.",
    "top_p": "Выборка по принципу top-p (также известная как nucleus): Этот метод уменьшает распределение вероятности и рассматривает только верхний p-процент токенов. Отбрасывая токены с низкой вероятностью, он помогает ограничить генерацию и предотвратить генерацию моделью грамматически неправильных предложений.",
    "typical_p": "Typical p: Типичная выборка — это информационно-теоретическая техника, которая, в дополнение к вероятности, учитывает энтропию последовательности (т.е. информационное содержание в соответствии с вероятностью). Это означает, что типичная выборка \"перевешивает\" некоторые токены с более низкой вероятностью, потому что они считаются \"интересными,\" и недовешивает токены с высокой вероятностью, потому что они считаются \"скучными.\""
  },
  "plugin_url_placeholder": "Введите URL Плагина",
  "plugins": "Плагины",
  "preset": "Предустановка",
  "preset_custom": "Собственная предустановка",
  "queue_info": "Ваше сообщение находится в очереди, вы на позиции {{ queuePosition, number, integer }}.",
  "remove_plugin": "Удалить Плагин",
  "repetition_penalty": "Штраф за повтор",
  "select_chat_notify": "Для продолжения выберите черновик.",
  "sponsored_by": "При поддержке",
  "temperature": "Температура",
  "top_k": "Top K",
  "top_p": "Top P",
  "typical_p": "Typical P",
  "unverified_plugin": "НЕПРОВЕРЕНО",
  "used": "Был использован",
  "verified_plugin": "ПРОВЕРЕНО",
  "verified_plugin_description": "Этот плагин был проверен командой Open Assistant.",
  "view_plugin": "Посмотреть Плагин",
  "visible_hidden": "Видимые и Скрытые",
  "unverified_plugin_description": "Этот плагин не был проверен командой Open Assistant. Используйте на свой страх и риск.",
  "you_are_logged_in": "Вы вошли в систему диалогов",
  "your_chats": "Ваши диалоги",
  "warning": "Open Assistant находится на ранних этапах разработки и на данный момент не имеет доступа в Интернет. Он может генерировать неверную или вводящую в заблуждение информацию. Он не подходит для решения важных задач или для выдачи рекомендаций.",
  "save_preset": "Сохранить предустановку",
  "preset_exists_error": "Предустановка с таким именем уже существует",
  "preset_name_placeholder": "Введите имя...",
  "feedback_message": "Вам понравился мой ответ? Ваш отзыв поможет мне стать лучше!",
  "feedback_action_great": "Отлично!",
  "feedback_action_poor": "Не очень...",
  "custom_instructions": "Свои инструкции",
  "custom_instructions_user_profile": "Какую информацию Open-Assistant должен иметь о вас, чтобы отвечать ещё лучше?",
  "custom_instructions_response_instructions": "Как вы хотите, чтобы Open-Assistant общался с вами?",
  "custom_instructions_user_profile_placeholder": "Перечислите свои мечты.\nОпишите свои увлечения и интересы.\nПоделитесь своим местонахождением.\nКакова ваша профессия.\nНа какие темы вы могли бы подробно поговорить?",
  "custom_instructions_response_instructions_placeholder": "Должен ли Open-Assistant выражать свое мнение или сохранять нейтралитет?\nУкажите желаемый уровень формальности в ответах Open-Assistant.\nКак Open-Assistant должен обращаться к Вам?\nОпределите предпочтительную длину ответов."
}
