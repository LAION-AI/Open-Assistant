{
  "back_to_chat_list": "チャットリストに戻る",
  "chat_date": "{{val, datetime}}",
  "config_title": "チャット設定",
  "empty": "Untitled",
  "login_message": "この機能を利用するには、再度ログインする必要があります。以下のプロバイダーのいずれかを使用してログインしてください:",
  "max_new_tokens": "最大新規トークン",
  "model": "モデル",
  "parameter_description": {
    "max_new_tokens": "最大新規トークン：このパラメータは、モデルが応答に対して生成すべき新規トークンの最大数を指定します。",
    "repetition_penalty": "繰り返しペナルティ：このパラメータは、繰り返しトークンを繰り返し生成する確率を、通常のモデルの予測よりも低くすることで、同じトークンの繰り返しを減らします。",
    "temperature": "温度: 生成する各トークンは、分布p(next_token|previous_tokens)からサンプリングされます。温度パラメータは、この分布を「鋭く」したり、「減衰」させたりできます。これを1に設定すると、モデルは予測される確率に基づいてトークンを生成します（つまり、「XYZ」が12.3%の確率で生成されると予測された場合、12.3%の確率で生成されます）。温度をゼロに近づけると、モデルはより貪欲になり、高い確率がさらに高くなり、低い確率がさらに低くなります（これは線形関係ではないことに注意！）。温度を上げると、すべての確率がより似てきます。直感的には、低温度ではモデルは自分の信念に密接に沿った回答を生成し、高温度ではより創造的で多様な回答が可能になります。",
    "top_k": "Top-k: これは top-p サンプリングに似ていますが、累積確率が 'p' を超えるまでのトップトークンを取る代わりに、最も確率の高い K のトークンのみを取ります。通常、モデルが検索半径を「チューニング」できるため、top-p が好まれますが、モデルが次に何を生成すべきかわからず、多くのトークンに非常に一様な分布を割り当てる場合、top-k は緊急ブレーキとして役立ちます。",
    "top_p": "Top-p（核とも呼ばれる）サンプリング: この方法は、トークンの上位pパーセントの確率分布のみを見るように確率分布を減らします。低確率のトークンを破棄することで、生成を制限し、モデルが文法的に正しくない文を生成するのを防ぎます。",
    "typical_p": "Typical p: 典型的なサンプリングは、確率に加えて、シーケンスエントロピー（すなわち、確率による情報量）も考慮する情報理論的手法です。これは、典型的なサンプリングが「興味深い」とされる低確率のトークンを「過剰評価」し、「つまらない」とされる高確率のトークンを「過小評価」することを意味します。"
  },
  "preset": "プリセット",
  "preset_custom": "カスタム",
  "queue_info": "あなたのメッセージはキューに入っており、キュー内の位置は {{ queuePosition, number, integer }} です。",
  "repetition_penalty": "繰り返しペナルティ",
  "temperature": "温度",
  "top_k": "Top K",
  "top_p": "Top P",
  "typical_p": "Typical P",
  "you_are_logged_in": "チャットサービスにログインしています",
  "your_chats": "あなたのチャット"
}
