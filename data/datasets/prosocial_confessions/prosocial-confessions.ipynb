{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "435c534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,Dataset\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "SBERT_MODEL = \"all-MiniLM-L6-v2\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.spatial as sp\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import faiss\n",
    "from collections import ChainMap\n",
    "from scipy.special import softmax\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch\n",
    "np.set_printoptions(precision=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c431d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "THRESHOLD = 0.72\n",
    "B_SIZE = 500\n",
    "MAXLEN = 196\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9e2aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectorizer(model=SBERT_MODEL):\n",
    "    return SentenceTransformer(model)\n",
    "\n",
    "\n",
    "def vectorize_text(model, texts):\n",
    "    return model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "def build_index(vector):\n",
    "    \n",
    "    d = vector.shape[1]\n",
    "    index = faiss.IndexFlatIP(d)\n",
    "    faiss.normalize_L2(rot_vector)\n",
    "    index.add(rot_vector)\n",
    "    return index\n",
    "    \n",
    "\n",
    "def get_conversations(rot_vector, posts_vector):\n",
    "    \n",
    "    index = build_index(rot_vector)\n",
    "    num_result=5\n",
    "    faiss.normalize_L2(posts_vector)\n",
    "    matching_dict = defaultdict(list)\n",
    "    for idx in tqdm(range(0, posts_vector.shape[0], B_SIZE)):\n",
    "        I, D = index.search(posts_vector[idx:idx+B_SIZE],num_result)\n",
    "        sim_indices = np.argwhere(I >= THRESHOLD)\n",
    "        #return sim_indices\n",
    "        for k, j in sim_indices:\n",
    "            matching_dict[k+idx].append({D[k][j]:I[k][j]})\n",
    "\n",
    "    return matching_dict\n",
    "\n",
    "def get_top_n(data,n=2):\n",
    "    \n",
    "    data = dict(ChainMap(*data))\n",
    "    data = {k: v for k, v in sorted(data.items(), key=lambda data: data[1],reverse=True)}\n",
    "    return list(data.keys())[:n]\n",
    "    \n",
    "\n",
    "def convert_to_json(match_dict,all_rots,reddit_df):\n",
    "    all_data = []\n",
    "    posts = reddit_df['title'].values\n",
    "    permalinks = reddit_df['permalink'].values\n",
    "    for post_id,rot_list in match_dict.items():\n",
    "        rot_ids = get_top_n(rot_list)\n",
    "        ps_rots = [all_rots[idx] for idx in rot_ids]\n",
    "        all_data.append({\"context\":posts[post_id], \"rots\":ps_rots,\"permalink\":permalinks[post_id],\"episone_done\":True})\n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f089487b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration allenai--prosocial-dialog-ebbad39ca08b6d44\n",
      "Found cached dataset json (/home/shahul/.cache/huggingface/datasets/allenai___json/allenai--prosocial-dialog-ebbad39ca08b6d44/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n",
      "/tmp/ipykernel_137805/1411690863.py:2: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  conf_df = pd.read_csv(\"/home/shahul/Data/one-million-reddit-confessions.csv\")\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"allenai/prosocial-dialog\",split=\"train\")\n",
    "conf_df = pd.read_csv(\"/home/shahul/Data/one-million-reddit-confessions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c86567c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_137805/162276847.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conf_df_filtered[\"title_len\"] = conf_df_filtered['title'].map(lambda x : len(x.split()))\n"
     ]
    }
   ],
   "source": [
    "conf_df_filtered = conf_df.query(\"score>3.0\")\n",
    "conf_df_filtered[\"title_len\"] = conf_df_filtered['title'].map(lambda x : len(x.split()))\n",
    "conf_df_filtered = conf_df_filtered.query(\"title_len>5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0a3d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "rots = [item[\"rots\"] for item in dataset]\n",
    "rots = set([x for item in rots for x in item])\n",
    "rots = list(rots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a169a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3580d6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f557db1d2f0e4527b9c4cf9fc74810a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rot_vector = vectorize_text(model, rots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "828a26ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c409c6b403b942c3b281add4999e2a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5431 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "posts = conf_df_filtered['title'].values.tolist()\n",
    "posts_vector = vectorize_text(model,posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bb4d884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████| 2/2 [00:03<00:00,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "match_dict = get_conversations(rot_vector,posts_vector[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4f6ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = convert_to_json(match_dict,rots,conf_df_filtered.head(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c1688a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "confession_dataset = Dataset.from_list(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b75efb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'i accused a family member of something they didn’t do',\n",
       " 'rots': ['It is understandable to be accused of something you did not do.',\n",
       "  \"You should get a lawyer if you're accused of something you didn't do.\"],\n",
       " 'permalink': 'https://old.reddit.com/r/confession/comments/pwv3h1/i_accused_a_family_member_of_something_they_didnt/',\n",
       " 'episone_done': True}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confession_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26477b70",
   "metadata": {},
   "source": [
    "## Pseudo label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "803ebd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = {\"__casual__\":0,\"__needs_caution__\":1,\"__needs_intervention__\":2,\"__probably_needs_caution__\":3,\"__possibly_needs_caution__\":4}\n",
    "id_to_label = {v:k for k,v in label_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2894b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ProSocialDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,dataset,tokenizer):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sep_token  = self.tokenizer.sep_token\n",
    "        self.dataset = dataset\n",
    "        self.label2id = label_to_id\n",
    "        self.id2label = {v:k for k,v in label_to_id.items()}\n",
    "        self.max_len = MAXLEN\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        encoding = {}\n",
    "\n",
    "        \n",
    "        context = self.dataset[idx][\"context\"]\n",
    "        rots = self.dataset[idx][\"rots\"]\n",
    "        input_tokens = self.tokenizer.encode(self.dataset[idx][\"context\"],add_special_tokens=False)\n",
    "        max_len = max(0,self.max_len - (len(input_tokens)+4))\n",
    "\n",
    "        rots = self.tokenizer.encode(self.tokenizer.sep_token.join(rots),\n",
    "                                     add_special_tokens=False,\n",
    "                                   max_length=max_len,)\n",
    "        \n",
    "        \n",
    "        input_ids = [0] + input_tokens + [self.tokenizer.sep_token_id] + rots + [self.tokenizer.eos_token_id]\n",
    "        input_ids = input_ids + [self.tokenizer.pad_token_id] * max(0,(self.max_len - len(input_ids)))\n",
    "        mask = [1]*len(input_ids) + [self.tokenizer.pad_token_id] * (self.max_len-len(input_ids))\n",
    "        \n",
    "        encoding[\"input_ids\"] = torch.tensor(input_ids)\n",
    "        encoding[\"attention_mask\"] = torch.tensor(mask)\n",
    "        \n",
    "        return encoding\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7a633bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"shahules786/prosocial-classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d1c061fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd1b24e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(pred_dataloader):\n",
    "    \n",
    "    probs, labels = [], []\n",
    "    for data in tqdm(pred_dataloader):\n",
    "        pred = softmax(\n",
    "            model(data[\"input_ids\"], data[\"attention_mask\"])\n",
    "            .logits.detach()\n",
    "            .numpy()\n",
    "            .astype(\"float16\"),\n",
    "            axis=1,\n",
    "        )\n",
    "        probs.append(pred.max(axis=1))\n",
    "        labels.append([model.config.id2label.get(pred_id) for pred_id in pred.argmax(axis=1)])\n",
    "\n",
    "    return np.concatenate(probs), np.concatenate(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3b58fed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = ProSocialDataset(confession_dataset,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a15f76a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = DataLoader(pred_dataset,batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "227b2067",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob,label=predict(pred_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "638e60e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "confession_dataset = confession_dataset.add_column(\"confidence\", prob)\n",
    "confession_dataset = confession_dataset.add_column(\"safety_label\", label)\n",
    "confession_dataset = confession_dataset.add_column(\"response\", [None]*len(confession_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8d6607a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'rots', 'permalink', 'episone_done', 'confidence', 'safety_label'],\n",
       "    num_rows: 44\n",
       "})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confession_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ad1ddabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'i accused a family member of something they didn’t do',\n",
       " 'rots': ['It is understandable to be accused of something you did not do.',\n",
       "  \"You should get a lawyer if you're accused of something you didn't do.\"],\n",
       " 'permalink': 'https://old.reddit.com/r/confession/comments/pwv3h1/i_accused_a_family_member_of_something_they_didnt/',\n",
       " 'episone_done': True,\n",
       " 'confidence': 0.4321,\n",
       " 'safety_label': '__needs_caution__'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confession_dataset.upload_to_hub(\"shahules786/prosocial-confessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a438c36e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenAssistant",
   "language": "python",
   "name": "openassistant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
