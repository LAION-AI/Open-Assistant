{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b2848c",
   "metadata": {},
   "source": [
    "# Diverse Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2e3c95c",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LAION-AI/Open-Assistant/blob/main/notebooks/data-augmentation/unified-qa/unified-qa.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81932b9",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to download the DIVERSE dataset and convert it into a format that can be used for training the OpenAssistant.\n",
    "\n",
    "The DIVERSE repo can be found here: https://github.com/microsoft/CodeT/tree/main/DIVERSE\n",
    "\n",
    "If you extend or use this work, please cite the relevant papers:\n",
    "```\n",
    "@article{li2022advance,\n",
    "  title={On the Advance of Making Language Models Better Reasoners},\n",
    "  author={Li, Yifei and Lin, Zeqi and Zhang, Shizhuo and Fu, Qiang and Chen, Bei and Lou, Jian-Guang and Chen, Weizhu},\n",
    "  journal={arXiv preprint arXiv:2206.02336},\n",
    "  year={2022}\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c98078",
   "metadata": {},
   "source": [
    "# OpenAssistant Data Scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2731f88f",
   "metadata": {},
   "source": [
    "We will use the data scheme that can be found in the docs for Open-Assistant. This code is taken from the StackExchange notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d35ab066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar, List, Dict, Any, Literal\n",
    "from json import JSONEncoder\n",
    "\n",
    "T = TypeVar(\"T\", bound=\"ConversationTreeNode\")\n",
    "\n",
    "\n",
    "class ConversationTreeNode:\n",
    "    text: str  # The text of the node\n",
    "    role: Literal[\"prompter\", \"assistant\"]  # Whether the node is a user prompt/follow-up or an assistant response\n",
    "    children: List[T]  # The children of the node (if you have a linear conversation, this will be of length 0 or 1)\n",
    "    metadata: Dict[str, Any]  # Node metadata (see below)\n",
    "\n",
    "    def __init__(\n",
    "        self, text: str, role: Literal[\"prompter\", \"assistant\"], children: List[T], metadata: Dict[str, Any]\n",
    "    ) -> None:\n",
    "        self.text = text\n",
    "        self.role = role\n",
    "        self.children = children\n",
    "        self.metadata = metadata\n",
    "\n",
    "\n",
    "class ConversationTree:\n",
    "    root: ConversationTreeNode  # The node containing the initial prompt\n",
    "    metadata: Dict[str, Any]  # Tree metadata, different from root node metadata.\n",
    "\n",
    "    def __init__(self, root: ConversationTreeNode, metadata: Dict[str, Any]) -> None:\n",
    "        self.root = root\n",
    "        self.metadata = metadata\n",
    "\n",
    "\n",
    "# subclass JSONEncoder\n",
    "class TreeEncoder(JSONEncoder):\n",
    "    def default(self, o):\n",
    "        return o.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7457bae",
   "metadata": {},
   "source": [
    "# Download and convert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b0fd63",
   "metadata": {},
   "source": [
    "We firstly import pandas and any other libraries that we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9317d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dc4e18",
   "metadata": {},
   "source": [
    "The following is a simple function to take the data (which has two columns) and convert it to a tree with a root note (question) and one child (answer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "963e0d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def convert_diverse(dataset_json_path):\n",
    "    # read files using pandas\n",
    "    ds = pd.read_json(dataset_json_path, lines=True)\n",
    "\n",
    "    # create dataset name from path\n",
    "    ds_name = \"diverse\"+ file.split(\"data\")[-1].replace(\"/\", \"_\").split(\".\")[0]\n",
    "\n",
    "    # create conversation forest\n",
    "    conversation_forest = []\n",
    "    for item in ds[\"context\"]:\n",
    "        # build nodes and tree\n",
    "        # Find all answers:\n",
    "\n",
    "        answers = re.findall(r'Answer:?(.*?)#', item.replace(\"\\n\", \" \"))\n",
    "        questions = re.findall(r'Question:?(.*?) Answer:', item.replace(\"\\n\", \" \"))\n",
    "\n",
    "        if len(answers) < len(questions):\n",
    "            questions.pop(-1)\n",
    "\n",
    "        for (question, answer) in zip(answers, questions):\n",
    "            root = ConversationTreeNode(text=question, role=\"prompter\", children=[], metadata=None)\n",
    "            child = ConversationTreeNode(text=answer, role=\"assistant\", children=[], metadata=None)\n",
    "            root.children.append(child)\n",
    "            conversation_tree = ConversationTree(root=root, metadata={\"dataset\": ds_name})\n",
    "            conversation_forest.append(conversation_tree)\n",
    "\n",
    "    conversation_forest_json = [\n",
    "        json.loads(TreeEncoder().encode(conversation_tree)) for conversation_tree in conversation_forest\n",
    "    ]\n",
    "\n",
    "    print(json.dumps(conversation_forest_json, indent=4), file=open(f\"./{ds_name}.json\", \"w+\"))\n",
    "    print(\"*****\", ds_name, \"****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4448c9a",
   "metadata": {},
   "source": [
    "We now clone the repository containing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CodeT'...\r\n",
      "remote: Enumerating objects: 144, done.\u001B[K\r\n",
      "remote: Counting objects: 100% (16/16), done.\u001B[K\r\n",
      "remote: Compressing objects: 100% (16/16), done.\u001B[K\r\n",
      "remote: Total 144 (delta 1), reused 0 (delta 0), pack-reused 128\u001B[K\r\n",
      "Receiving objects: 100% (144/144), 56.76 MiB | 8.89 MiB/s, done.\r\n",
      "Resolving deltas: 100% (33/33), done.\r\n",
      "Updating files: 100% (64/64), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/microsoft/CodeT.git"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "diverse_files = [\n",
    "    \"CodeT/DIVERSE/data/sqa/split1/test.jsonl\",\n",
    "    \"CodeT/DIVERSE/data/sqa/split1/train.jsonl\",\n",
    "    \"CodeT/DIVERSE/data/sqa/split2/test.jsonl\",\n",
    "    \"CodeT/DIVERSE/data/sqa/split2/train.jsonl\",\n",
    "    \"CodeT/DIVERSE/data/gsm8k/test.jsonl\",\n",
    "    \"CodeT/DIVERSE/data/gsm8k/train.jsonl\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "for file in diverse_files:\n",
    "    convert_diverse(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "25d5c2324055587ceaeef27650c79ce8358ea61d7689f2e0b8ada5d53f85bce4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
