{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f80b8618-abf6-4763-89d9-20b831c4ea98",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hippocorpus converter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b545caa0-0a32-4007-8f17-8fbdc2f1dd37",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefa8aac-4ab9-4b5a-b3e0-c65baa8da873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hippocorpus = pd.read_csv(\"hippocorpus/hcV3-stories.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf19352-7c90-4bdf-bc90-5e328e64161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a surprising number of people who seem to have left capslock on while participating in the data collection process.\n",
    "# These entries tend to be of lower than average quality and would be impossible to fully restore without more complex methods, so they are excluded\n",
    "hippocorpus = hippocorpus[~hippocorpus[\"mainEvent\"].str.isupper()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968bbf1e-78b3-4436-8a3f-9335b4d2801a",
   "metadata": {},
   "source": [
    "## Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d1fb4e-fe06-4c6c-b3a0-f4dec5b8663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    \"WorkTimeInSeconds\",\n",
    "    \"WorkerId\",\n",
    "    \"annotatorAge\",\n",
    "    \"annotatorGender\",\n",
    "    \"annotatorRace\",\n",
    "    \"distracted\",\n",
    "    \"draining\",\n",
    "    \"frequency\",\n",
    "    \"importance\",\n",
    "    \"logTimeSinceEvent\",\n",
    "    \"memType\",\n",
    "    \"mostSurprising\",\n",
    "    \"openness\",\n",
    "    \"recAgnPairId\",\n",
    "    \"recImgPairId\",\n",
    "    \"similarity\",\n",
    "    \"similarityReason\",\n",
    "    \"stressful\",\n",
    "    \"summary\",\n",
    "    \"timeSinceEvent\",\n",
    "]\n",
    "hippocorpus = hippocorpus.drop(cols_to_drop, axis=1)\n",
    "hippocorpus.columns = [\"SOURCE\", \"INSTRUCTION\", \"RESPONSE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd02ee-618f-4d02-8856-e98a245cd50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hippocorpus[[\"SOURCE\"]] = \"Hippocorpus: \" + hippocorpus[[\"SOURCE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec73fd44-b209-4bea-a1c9-711251747647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from random import choice, random, randrange\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "\n",
    "def replace_my(string):\n",
    "    match = re.search(r\"my (\\w+)\", string)\n",
    "    if match:\n",
    "        word = match.group(1)\n",
    "        if word[0] in \"aeiou\":\n",
    "            string = re.sub(r\"my\", \"an\", string, 1)\n",
    "        else:\n",
    "            string = re.sub(r\"my\", \"a\", string, 1)\n",
    "    return string\n",
    "\n",
    "\n",
    "def convert_row(row):\n",
    "    orig_instruction = row[\"INSTRUCTION\"].rstrip(\"!.?;:\")\n",
    "    orig_instruction = orig_instruction[0].lower() + orig_instruction[1:]\n",
    "    orig_instruction = replace_my(orig_instruction)\n",
    "    orig_response = row[\"RESPONSE\"]\n",
    "    n_original = choice([\"\", \"n original\"])\n",
    "    instruction = f\"Write a{n_original} story about {orig_instruction}.\"\n",
    "    do_sentence_instruction = random() > 0.5\n",
    "    if do_sentence_instruction:\n",
    "        sentences = sent_tokenize(orig_response)\n",
    "        sentence_index = randrange(len(sentences))\n",
    "        if sentence_index == 0:\n",
    "            instruction += \" Make the first sentence \"\n",
    "            sentence_response_section = f\" where the first sentence is \"\n",
    "        elif sentence_index == len(sentences) - 1:\n",
    "            instruction += \" Make the last sentence \"\n",
    "            sentence_response_section = f\" where the last sentence is \"\n",
    "        else:\n",
    "            instruction += \" Include the sentence \"\n",
    "            sentence_response_section = f\" which includes the sentence \"\n",
    "        instruction += f'\"{sentences[sentence_index]}\"'\n",
    "        sentence_response_section += f'\"{sentences[sentence_index]}\"'\n",
    "    else:\n",
    "        sentence_response_section = \"\"\n",
    "    sure = choice([\"Sure\", \"Of course\", \"Alright\", \"Certainly\"])\n",
    "    punctuation = choice([\",\", \"!\", \".\"])\n",
    "    response = (\n",
    "        f\"{sure}{punctuation} Here's a story about {orig_instruction}{sentence_response_section}.\\n\\n{orig_response}\"\n",
    "    )\n",
    "    row[\"INSTRUCTION\"] = instruction\n",
    "    row[\"RESPONSE\"] = response\n",
    "    return row\n",
    "\n",
    "\n",
    "hippocorpus.apply(convert_row, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fadffd-f0b0-44f9-abf5-41fad3c26738",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0d047d-8cb4-4621-80bc-630545c1c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "table = pa.Table.from_pandas(hippocorpus)\n",
    "pq.write_table(table, \"data.parquet\", row_group_size=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Open-Assistant",
   "language": "python",
   "name": "open-assistant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
