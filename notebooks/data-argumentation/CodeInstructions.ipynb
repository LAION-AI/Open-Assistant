{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "private_outputs": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install --quiet tokenizers\n",
    "!pip install --quiet transformers\n",
    "!pip install --quiet sentencepiece"
   ],
   "metadata": {
    "id": "qD7RgTDIpFWq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZSDgwXQo2cB"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Graverman/t5-code-summary\")\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Graverman/t5-code-summary\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_answer(code):\n",
    "    source_encoding = tokenizer(\n",
    "        code,\n",
    "        max_length=300,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=source_encoding[\"input_ids\"],\n",
    "        attention_mask=source_encoding[\"attention_mask\"],\n",
    "        num_beams=1,\n",
    "        max_length=100,\n",
    "        repetition_penalty=2.5,\n",
    "        length_penalty=0.75,\n",
    "        early_stopping=True,\n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "    preds = [\n",
    "        tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        for gen_id in generated_ids\n",
    "    ]\n",
    "\n",
    "    return \"\".join(preds)"
   ],
   "metadata": {
    "id": "r44ukPINo3KI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "code = \"\"\"\n",
    "def Suduko(grid, row, col):\n",
    " \n",
    "    if (row == M - 1 and col == M):\n",
    "        return True\n",
    "    if col == M:\n",
    "        row += 1\n",
    "        col = 0\n",
    "    if grid[row][col] > 0:\n",
    "        return Suduko(grid, row, col + 1)\n",
    "    for num in range(1, M + 1, 1): \n",
    "     \n",
    "        if solve(grid, row, col, num):\n",
    "         \n",
    "            grid[row][col] = num\n",
    "            if Suduko(grid, row, col + 1):\n",
    "                return True\n",
    "        grid[row][col] = 0\n",
    "    return False\n",
    "\"\"\"  # This code results in some bad grammar but correct answer"
   ],
   "metadata": {
    "id": "1rcDuijlo5F3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generate_answer(code)"
   ],
   "metadata": {
    "id": "vXtg_IR4msxo"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
